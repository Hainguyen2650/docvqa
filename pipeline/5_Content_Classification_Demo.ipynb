{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Content Classification Demo\n",
    "\n",
    "Demo notebook ƒë·ªÉ ph√¢n lo·∫°i n·ªôi dung OCR output v√† v·∫Ω bounding boxes.\n",
    "\n",
    "## C√°c lo·∫°i n·ªôi dung ƒë∆∞·ª£c ph√¢n lo·∫°i:\n",
    "- **TABLE** (ƒê·ªè): B·∫£ng d·ªØ li·ªáu v·ªõi c√°c c·ªôt v√† h√†ng\n",
    "- **FORM** (Xanh d∆∞∆°ng): Form v·ªõi c√°c c·∫∑p key:value\n",
    "- **FIGURE** (Xanh l√°): Chart, plot, bi·ªÉu ƒë·ªì\n",
    "- **TEXT** (Cam): ƒêo·∫°n vƒÉn b·∫£n th√¥ng th∆∞·ªùng\n",
    "\n",
    "## Output:\n",
    "- ·∫¢nh v·ªõi bounding boxes ƒë∆∞·ª£c t√¥ m√†u theo lo·∫°i n·ªôi dung\n",
    "- JSON file v·ªõi classification results\n",
    "- Comparison view v√† Type grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Import modules\n",
    "from src.ocr import (\n",
    "    PaddleOCRProcessor,\n",
    "    ContentClassifier,\n",
    "    ContentType,\n",
    "    BBoxVisualizer,\n",
    "    visualize_classification,\n",
    "    create_demo_output\n",
    ")\n",
    "\n",
    "print(\"‚úì Modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kh·ªüi t·∫°o OCR Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o processor\n",
    "processor = PaddleOCRProcessor()\n",
    "print(\"‚úì OCR Processor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. T√¨m ·∫£nh m·∫´u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√¨m ·∫£nh m·∫´u trong dataset\n",
    "image_paths = glob.glob('../dataset/DocVQA_Images/**/*.png', recursive=True)\n",
    "if not image_paths:\n",
    "    image_paths = glob.glob('../dataset/**/*.png', recursive=True)\n",
    "if not image_paths:\n",
    "    image_paths = glob.glob('../**/*.png', recursive=True)\n",
    "\n",
    "if image_paths:\n",
    "    sample_image = image_paths[0]\n",
    "    print(f\"·∫¢nh m·∫´u: {sample_image}\")\n",
    "else:\n",
    "    sample_image = None\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh m·∫´u. Vui l√≤ng ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n ·∫£nh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ch·∫°y OCR v√† Ph√¢n lo·∫°i n·ªôi dung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image:\n",
    "    # Ch·∫°y OCR v·ªõi ph√¢n lo·∫°i n·ªôi dung\n",
    "    ocr_result, classification = processor.run_ocr_with_classification(\n",
    "        sample_image,\n",
    "        use_preprocessing=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"K·∫æT QU·∫¢ OCR\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"S·ªë d√≤ng ph√°t hi·ªán: {ocr_result['num_lines']}\")\n",
    "    print(f\"ƒê·ªô tin c·∫≠y TB: {ocr_result['avg_confidence']:.2%}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"K·∫æT QU·∫¢ PH√ÇN LO·∫†I\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Tables (B·∫£ng):    {classification.summary.get('table', 0)}\")\n",
    "    print(f\"Forms (Key:Value): {classification.summary.get('form', 0)}\")\n",
    "    print(f\"Figures (Chart):  {classification.summary.get('figure', 0)}\")\n",
    "    print(f\"Text (Paragraph): {classification.summary.get('text', 0)}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hi·ªÉn th·ªã chi ti·∫øt c√°c regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image and classification.regions:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"CHI TI·∫æT C√ÅC REGIONS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for region in classification.regions:\n",
    "        print(f\"\\n[Region {region.region_id}] {region.content_type.value.upper()}\")\n",
    "        print(f\"  Confidence: {region.confidence:.3f}\")\n",
    "        print(f\"  Lines: {len(region.lines)}\")\n",
    "        \n",
    "        # In metadata theo lo·∫°i\n",
    "        if region.content_type == ContentType.TABLE:\n",
    "            print(f\"  Columns: {region.metadata.get('num_columns', 0)}\")\n",
    "            print(f\"  Column Stability: {region.metadata.get('column_stability', 0):.2f}\")\n",
    "        elif region.content_type == ContentType.FORM:\n",
    "            print(f\"  Key:Value Pattern: {region.metadata.get('has_keyvalue_pattern', False)}\")\n",
    "            print(f\"  Colon Ratio: {region.metadata.get('colon_ratio', 0):.2f}\")\n",
    "        elif region.content_type == ContentType.FIGURE:\n",
    "            print(f\"  Empty Center: {region.metadata.get('empty_center_ratio', 0):.2f}\")\n",
    "            print(f\"  Has Legend: {region.metadata.get('has_legend', False)}\")\n",
    "        elif region.content_type == ContentType.TEXT:\n",
    "            print(f\"  Avg Line Length: {region.metadata.get('avg_line_length', 0):.1f}\")\n",
    "            print(f\"  Spacing Uniformity: {region.metadata.get('spacing_uniformity', 0):.2f}\")\n",
    "        \n",
    "        # Preview text content\n",
    "        if region.text_content:\n",
    "            preview = region.text_content[:100].replace('\\n', ' ')\n",
    "            print(f\"  Preview: {preview}...\" if len(region.text_content) > 100 else f\"  Preview: {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization - Bounding Boxes v·ªõi m√†u theo lo·∫°i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image and classification.regions:\n",
    "    # V·∫Ω bounding boxes\n",
    "    img_classified = processor.draw_classified_regions(\n",
    "        sample_image,\n",
    "        classification,\n",
    "        fill=True\n",
    "    )\n",
    "    \n",
    "    # Hi·ªÉn th·ªã\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # ·∫¢nh g·ªëc\n",
    "    axes[0].imshow(Image.open(sample_image))\n",
    "    axes[0].set_title('·∫¢nh g·ªëc', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # ·∫¢nh v·ªõi classification\n",
    "    axes[1].imshow(img_classified)\n",
    "    axes[1].set_title('Content Classification\\n(Red=Table, Blue=Form, Green=Figure, Orange=Text)', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image and classification.regions:\n",
    "    # T·∫°o comparison view\n",
    "    visualizer = BBoxVisualizer()\n",
    "    comparison_img = visualizer.create_comparison_view(sample_image, classification)\n",
    "    \n",
    "    plt.figure(figsize=(24, 10))\n",
    "    plt.imshow(comparison_img)\n",
    "    plt.title('Comparison: Original ‚Üí OCR Detected ‚Üí Content Classified', fontsize=16, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Type Grid View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image and classification.regions:\n",
    "    # T·∫°o type grid\n",
    "    type_grid_img = visualizer.create_type_grid(sample_image, classification)\n",
    "    \n",
    "    plt.figure(figsize=(20, 16))\n",
    "    plt.imshow(type_grid_img)\n",
    "    plt.title('Content Type Grid', fontsize=16, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. L·ªçc theo lo·∫°i n·ªôi dung c·ª• th·ªÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image:\n",
    "    # Ch·ªâ hi·ªÉn th·ªã tables v√† forms\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # Ch·ªâ Tables\n",
    "    img_tables = processor.visualize_content_types(\n",
    "        sample_image,\n",
    "        ocr_result,\n",
    "        content_types=[ContentType.TABLE]\n",
    "    )\n",
    "    axes[0].imshow(img_tables)\n",
    "    axes[0].set_title(f'Ch·ªâ TABLES (ƒê·ªè)\\n({classification.summary.get(\"table\", 0)} detected)', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Ch·ªâ Forms\n",
    "    img_forms = processor.visualize_content_types(\n",
    "        sample_image,\n",
    "        ocr_result,\n",
    "        content_types=[ContentType.FORM]\n",
    "    )\n",
    "    axes[1].imshow(img_forms)\n",
    "    axes[1].set_title(f'Ch·ªâ FORMS (Xanh d∆∞∆°ng)\\n({classification.summary.get(\"form\", 0)} detected)', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tr√≠ch xu·∫•t n·ªôi dung theo lo·∫°i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification and classification.regions:\n",
    "    # L·∫•y t·∫•t c·∫£ tables\n",
    "    tables = classification.get_tables()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TABLES ({len(tables)} found)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for i, table in enumerate(tables, 1):\n",
    "        print(f\"\\nTable {i} (confidence: {table.confidence:.3f})\")\n",
    "        print(\"-\" * 40)\n",
    "        for line in table.lines[:5]:  # Preview 5 d√≤ng ƒë·∫ßu\n",
    "            print(f\"  {line}\")\n",
    "        if len(table.lines) > 5:\n",
    "            print(f\"  ... ({len(table.lines) - 5} more lines)\")\n",
    "    \n",
    "    # L·∫•y t·∫•t c·∫£ forms\n",
    "    forms = classification.get_forms()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FORMS ({len(forms)} found)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for i, form in enumerate(forms, 1):\n",
    "        print(f\"\\nForm {i} (confidence: {form.confidence:.3f})\")\n",
    "        print(\"-\" * 40)\n",
    "        for line in form.lines[:5]:\n",
    "            print(f\"  {line}\")\n",
    "        if len(form.lines) > 5:\n",
    "            print(f\"  ... ({len(form.lines) - 5} more lines)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Demo Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image:\n",
    "    # T·∫°o b·ªô demo outputs ƒë·∫ßy ƒë·ªß\n",
    "    output_dir = '../demo_output'\n",
    "    \n",
    "    results = processor.create_demo_visualization(\n",
    "        sample_image,\n",
    "        ocr_result=ocr_result,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # Hi·ªÉn th·ªã paths\n",
    "    if results['output_paths']:\n",
    "        print(f\"\\n‚úÖ Demo outputs saved:\")\n",
    "        for key, path in results['output_paths'].items():\n",
    "            print(f\"   - {key}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Quick API Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick API - One-liner classification\n",
    "if sample_image:\n",
    "    from src.ocr import classify_ocr_output, visualize_classification\n",
    "    \n",
    "    # Quick classify\n",
    "    quick_classification = classify_ocr_output(ocr_result)\n",
    "    print(f\"Quick Classification Summary: {quick_classification.summary}\")\n",
    "    \n",
    "    # Quick visualize\n",
    "    img, result = visualize_classification(\n",
    "        sample_image,\n",
    "        ocr_result,\n",
    "        output_path='../demo_output/quick_viz.png',\n",
    "        show=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legend\n",
    "\n",
    "| Color | Content Type | Description |\n",
    "|-------|--------------|-------------|\n",
    "| üî¥ Red | TABLE | B·∫£ng d·ªØ li·ªáu v·ªõi c√°c c·ªôt v√† h√†ng |\n",
    "| üîµ Blue | FORM | Form v·ªõi c√°c c·∫∑p key:value |\n",
    "| üü¢ Green | FIGURE | Chart, plot, bi·ªÉu ƒë·ªì |\n",
    "| üü† Orange | TEXT | ƒêo·∫°n vƒÉn b·∫£n th√¥ng th∆∞·ªùng |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
